{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "filename = '13 million Duolingo student learning traces.csv'\n",
    "filepath = os.path.normpath(os.path.join(current_dir, '../data/', filename))\n",
    "\n",
    "\n",
    "chunk_size = 10000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(filepath, chunksize=chunk_size):\n",
    "    chunk.drop_duplicates(inplace=True)\n",
    "    chunk.dropna(inplace=True)\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPOTHESIS 1 \n",
    "\"\"\" Instead of the sparse indicator variables used here, it may be better to decompose lexeme tags \n",
    "into denser and more generic features of tag components (e.g., part of speech, tense, gender, case), \n",
    "and also use corpus frequency, word length, etc.\"\"\"\n",
    "lexeme_filepath = os.path.normpath(os.path.join(current_dir, '../data/', 'lexeme_reference.csv'))\n",
    "lexeme_reference = pd.read_csv(lexeme_filepath, sep = ';', header=None, on_bad_lines='warn', \n",
    "                               names=[\"tag\", \"type\", \"description\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjective</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animacy</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propernoun</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tense</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tag  description\n",
       "type                        \n",
       "POS          22           22\n",
       "adjective    18           18\n",
       "animacy       3            3\n",
       "case          2            2\n",
       "def           2            2\n",
       "gender        5            5\n",
       "number        4            4\n",
       "other        14           14\n",
       "person        3            3\n",
       "propernoun    2            2\n",
       "tense        17           17"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes_grouped = lexeme_reference.groupby('type')\n",
    "lexemes_grouped.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adj': 'POS',\n",
       " 'adv': 'POS',\n",
       " 'cni': 'tense',\n",
       " 'cnjadv': 'POS',\n",
       " 'cnjcoo': 'POS',\n",
       " 'cnjsub': 'POS',\n",
       " 'def': 'def',\n",
       " 'det': 'POS',\n",
       " 'f': 'gender',\n",
       " 'fti': 'tense',\n",
       " 'fts': 'tense',\n",
       " 'GD': 'gender',\n",
       " 'ger': 'tense',\n",
       " 'ifi': 'tense',\n",
       " 'ij': 'POS',\n",
       " 'imp': 'tense',\n",
       " 'ind': 'def',\n",
       " 'inf': 'tense',\n",
       " 'm': 'gender',\n",
       " 'mf': 'gender',\n",
       " 'n': 'POS',\n",
       " 'ND': 'number',\n",
       " 'np': 'POS',\n",
       " 'nt': 'gender',\n",
       " 'num': 'POS',\n",
       " 'p1': 'person',\n",
       " 'p2': 'person',\n",
       " 'p3': 'person',\n",
       " 'past': 'tense',\n",
       " 'pii': 'tense',\n",
       " 'pis': 'tense',\n",
       " 'pl': 'number',\n",
       " 'pp': 'tense',\n",
       " 'pprs': 'tense',\n",
       " 'pr': 'POS',\n",
       " 'preadv': 'POS',\n",
       " 'predet': 'POS',\n",
       " 'pres': 'tense',\n",
       " 'pri': 'tense',\n",
       " 'prn': 'POS',\n",
       " 'pron': 'tense',\n",
       " 'prpers': 'POS',\n",
       " 'prs': 'tense',\n",
       " 'sent': 'POS',\n",
       " 'sg': 'number',\n",
       " 'sp': 'number',\n",
       " 'subs': 'tense',\n",
       " 'vaux': 'POS',\n",
       " 'vbdo': 'POS',\n",
       " 'vbhaver': 'POS',\n",
       " 'vblex': 'POS',\n",
       " 'vbmod': 'POS',\n",
       " 'vbser': 'POS'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tags_reference(df): \n",
    "    df = df[df[\"type\"].str.contains(\"adjective|animacy|other|propernoun|case\") == False]\n",
    "    tags_dict = df.set_index('tag')['type'].to_dict()\n",
    "    types = set(tags_dict.values())\n",
    "    return tags_dict, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dict, types = prepare_tags_reference(lexeme_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lexeme_type in types:\n",
    "    df[lexeme_type] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "      <th>gender</th>\n",
       "      <th>POS</th>\n",
       "      <th>def</th>\n",
       "      <th>tense</th>\n",
       "      <th>person</th>\n",
       "      <th>number</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>76390c1350a8dac31186187e2fe1e178</td>\n",
       "      <td>lernt/lernen&lt;vblex&gt;&lt;pri&gt;&lt;p3&gt;&lt;sg&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vblex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pri</td>\n",
       "      <td>p3</td>\n",
       "      <td>sg</td>\n",
       "      <td>[vblex, pri, p3, sg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>7dfd7086f3671685e2cf1c1da72796d7</td>\n",
       "      <td>die/die&lt;det&gt;&lt;def&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>det</td>\n",
       "      <td>def</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>[det, def, f, sg, nom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>35a54c25a2cda8127343f6a82e6f6b7d</td>\n",
       "      <td>mann/mann&lt;n&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>[n, m, sg, nom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>0cf63ffe3dda158bc3dbd55682b355ae</td>\n",
       "      <td>frau/frau&lt;n&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>[n, f, sg, nom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>84920990d78044db53c1b012f5bf9ab5</td>\n",
       "      <td>das/das&lt;det&gt;&lt;def&gt;&lt;nt&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>nt</td>\n",
       "      <td>det</td>\n",
       "      <td>def</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>[det, def, nt, sg, nom]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>228208</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>7e416735d7d43c3c0fc30d10801a352d</td>\n",
       "      <td>si/si&lt;cnjadv&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnjadv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cnjadv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>64651</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>69faeef930a44421ec22be4b06474a06</td>\n",
       "      <td>aunque/aunque&lt;cnjadv&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnjadv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cnjadv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>64651</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>8a100871aa249eeef95c20f864b281a1</td>\n",
       "      <td>mientras/mientras&lt;cnjadv&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cnjadv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[cnjadv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>442104</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>a764900ace90aa45b2466e3cb031072e</td>\n",
       "      <td>caminas/caminar&lt;vblex&gt;&lt;pri&gt;&lt;p2&gt;&lt;sg&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>vblex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pri</td>\n",
       "      <td>p2</td>\n",
       "      <td>sg</td>\n",
       "      <td>[vblex, pri, p2, sg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>442233</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>86584daef5933b284384453795bbf0ed</td>\n",
       "      <td>hombre/hombre&lt;n&gt;&lt;m&gt;&lt;sg&gt;</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>m</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>[n, m, sg]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_recall   timestamp     delta user_id learning_language ui_language  \\\n",
       "0   1.000000  1362076081  27649635    u:FO                de          en   \n",
       "1   0.500000  1362076081  27649635    u:FO                de          en   \n",
       "2   1.000000  1362076081  27649635    u:FO                de          en   \n",
       "3   0.500000  1362076081  27649635    u:FO                de          en   \n",
       "4   1.000000  1362076081  27649635    u:FO                de          en   \n",
       "..       ...         ...       ...     ...               ...         ...   \n",
       "95  0.666667  1362082511    228208  u:fxGh                es          en   \n",
       "96  1.000000  1362082511     64651  u:fxGh                es          en   \n",
       "97  1.000000  1362082511     64651  u:fxGh                es          en   \n",
       "98  1.000000  1362082511    442104  u:fxGh                es          en   \n",
       "99  1.000000  1362082511    442233  u:fxGh                es          en   \n",
       "\n",
       "                           lexeme_id                        lexeme_string  \\\n",
       "0   76390c1350a8dac31186187e2fe1e178     lernt/lernen<vblex><pri><p3><sg>   \n",
       "1   7dfd7086f3671685e2cf1c1da72796d7        die/die<det><def><f><sg><nom>   \n",
       "2   35a54c25a2cda8127343f6a82e6f6b7d             mann/mann<n><m><sg><nom>   \n",
       "3   0cf63ffe3dda158bc3dbd55682b355ae             frau/frau<n><f><sg><nom>   \n",
       "4   84920990d78044db53c1b012f5bf9ab5       das/das<det><def><nt><sg><nom>   \n",
       "..                               ...                                  ...   \n",
       "95  7e416735d7d43c3c0fc30d10801a352d                        si/si<cnjadv>   \n",
       "96  69faeef930a44421ec22be4b06474a06                aunque/aunque<cnjadv>   \n",
       "97  8a100871aa249eeef95c20f864b281a1            mientras/mientras<cnjadv>   \n",
       "98  a764900ace90aa45b2466e3cb031072e  caminas/caminar<vblex><pri><p2><sg>   \n",
       "99  86584daef5933b284384453795bbf0ed              hombre/hombre<n><m><sg>   \n",
       "\n",
       "    history_seen  history_correct  session_seen  session_correct gender  \\\n",
       "0              6                4             2                2    NaN   \n",
       "1              4                4             2                1      f   \n",
       "2              5                4             1                1      m   \n",
       "3              6                5             2                1      f   \n",
       "4              4                4             1                1     nt   \n",
       "..           ...              ...           ...              ...    ...   \n",
       "95             3                3             3                2    NaN   \n",
       "96             4                4             1                1    NaN   \n",
       "97             4                4             1                1    NaN   \n",
       "98             6                5             1                1    NaN   \n",
       "99            22               20             2                2      m   \n",
       "\n",
       "       POS  def tense person number                     tags  \n",
       "0    vblex  NaN   pri     p3     sg     [vblex, pri, p3, sg]  \n",
       "1      det  def   NaN    NaN     sg   [det, def, f, sg, nom]  \n",
       "2        n  NaN   NaN    NaN     sg          [n, m, sg, nom]  \n",
       "3        n  NaN   NaN    NaN     sg          [n, f, sg, nom]  \n",
       "4      det  def   NaN    NaN     sg  [det, def, nt, sg, nom]  \n",
       "..     ...  ...   ...    ...    ...                      ...  \n",
       "95  cnjadv  NaN   NaN    NaN    NaN                 [cnjadv]  \n",
       "96  cnjadv  NaN   NaN    NaN    NaN                 [cnjadv]  \n",
       "97  cnjadv  NaN   NaN    NaN    NaN                 [cnjadv]  \n",
       "98   vblex  NaN   pri     p2     sg     [vblex, pri, p2, sg]  \n",
       "99       n  NaN   NaN    NaN     sg               [n, m, sg]  \n",
       "\n",
       "[100 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_lexemestring(lexeme_string):\n",
    "    tags = re.findall(r'<(.*?)>', lexeme_string)\n",
    "    return tags \n",
    "\n",
    "# df['tags'] = df['lexeme_string'].apply(extract_from_lexemestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tags(tags):\n",
    "    values = {'gender': np.nan, 'POS': np.nan, 'def': np.nan, 'tense':np.nan, 'person':np.nan, 'number':np.nan}\n",
    "    for tag in tags:\n",
    "        col = tags_dict.get(tag)\n",
    "        if col and pd.isna(values[col]):  # Only assign if column is empty \n",
    "            values[col] = tag\n",
    "    return pd.Series([values['gender'], values['POS'],  values['def'], values['tense'], values['person'], values['number']])\n",
    "\n",
    "df[['gender', 'POS', 'def', 'tense', 'person', 'number']] = df['tags'].apply(assign_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features \n",
    "df['word'] = df['lexeme_string'].str.split(\"/\").str[0]\n",
    "df['word_len'] = df['word'].apply(lambda x: len(x))\n",
    "\n",
    "# Interaction feature \n",
    "df['lang_combination'] = df['ui_language'] + '-' + df['learning_language']\n",
    "\n",
    "# Drop columns \n",
    "df.drop(columns=['tags', 'lexeme_string', 'lexeme_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique users 115222\n"
     ]
    }
   ],
   "source": [
    "# HYPOTHESIS 2 \n",
    "\"\"\" User embeddings\"\"\" \n",
    "print('number of unique users', df['user_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = df.groupby('user_id').agg({'delta':'mean', 'p_recall':'mean', 'history_seen':'mean', 'history_correct':'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>delta</th>\n",
       "      <th>p_recall</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.152220e+05</td>\n",
       "      <td>115222.000000</td>\n",
       "      <td>115222.000000</td>\n",
       "      <td>115222.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.381635e+06</td>\n",
       "      <td>0.893688</td>\n",
       "      <td>8.667307</td>\n",
       "      <td>7.730473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.982971e+06</td>\n",
       "      <td>0.092706</td>\n",
       "      <td>16.454787</td>\n",
       "      <td>15.125486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.476660e+04</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>3.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.843964e+05</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>5.604651</td>\n",
       "      <td>4.944444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.217518e+06</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>9.367780</td>\n",
       "      <td>8.345135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.975832e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1756.652794</td>\n",
       "      <td>1683.241974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              delta       p_recall   history_seen  history_correct\n",
       "count  1.152220e+05  115222.000000  115222.000000    115222.000000\n",
       "mean   1.381635e+06       0.893688       8.667307         7.730473\n",
       "std    2.982971e+06       0.092706      16.454787        15.125486\n",
       "min    1.000000e+00       0.000000       1.000000         1.000000\n",
       "25%    9.476660e+04       0.861111       3.800000         3.303030\n",
       "50%    3.843964e+05       0.909091       5.604651         4.944444\n",
       "75%    1.217518e+06       0.950000       9.367780         8.345135\n",
       "max    3.975832e+07       1.000000    1756.652794      1683.241974"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

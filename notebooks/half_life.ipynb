{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ee633-14e5-4fca-81b2-bda39cce72da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Half-Life as implemented by Duolingo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "40860931-8de0-4f58-99e0-98d42682107d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from collections import defaultdict, namedtuple\n",
    "from sys import intern\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "81ed1b7c-e173-48bc-9bf9-552d7b3ba86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "filename = 'df_processed.csv'\n",
    "filepath = os.path.normpath(os.path.join(current_dir, '../data/processed/', filename))\n",
    "\n",
    "chunk_size = 10000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(filepath, chunksize=chunk_size):\n",
    "    chunk.drop_duplicates(inplace=True)\n",
    "    chunk.dropna(inplace=True)\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "df_users = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../data/features/', 'users_behaviur.csv')))\n",
    "df_words = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../data/features/', 'word_complexity_features.csv')), sep='\\t')\n",
    "\n",
    "df_1 = df.merge(df_words, on = 'lexeme_id', how='inner')\n",
    "df_1['lang_combination'] = df_1['ui_language']+ '-' + df_1['learning_language']\n",
    "df_2 = df_1.merge(df_users, on = ['user_id', 'lang_combination'], how='inner')\n",
    "dff = df_2.drop(columns=['timestamp', 'lexeme_id', 'word', 'user_id', 'POS', 'person', 'number', 'gender', 'tense', 'def', 'session_seen', 'session_correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d4309558-59fd-4d78-b51b-e7654bfba390",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame({'lang':[1,2,3], 'halo':[0.01, 0, 0.99]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7c63137d-f146-4c0e-8f14-87bc753d919f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_recall', 'delta', 'learning_language_x', 'ui_language_x',\n",
       "       'history_seen', 'history_correct', 'h_recall', 'word_len', 'SUBTLEX',\n",
       "       'lang_combination', 'learning_language_y', 'ui_language_y', 'avg_delta',\n",
       "       'avg_user_p_recall', 'std_delta', 'avg_h_recall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8e0a2111-0907-43e0-8d29-85929abc9f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes to dataset before fitting \n",
    "dff['p_recall'] = pclip(dff['p_recall'])\n",
    "dff['delta'] = dff['delta']/(60*60*24) # convert time delta to days\n",
    "# dff['half_life'] = hclip(-dff['delta']/np.log2(dff['p_recall']))\n",
    "# tag_counts = dff['tags_list'].value_counts()\n",
    "# rare_threshold = 1000\n",
    "# dff['tags_list'] = dff['tags_list'].apply(lambda x: x if tag_counts[x] > rare_threshold else 'rare')\n",
    "\n",
    "\n",
    "dff_final = dff.drop(columns=['learning_language_y', 'ui_language_y', 'learning_language_x', 'ui_language_x', 'avg_user_p_recall'], errors='ignore')\n",
    "dff_final.dropna(inplace=True)\n",
    "\n",
    "# original                 \n",
    "# h = hclip(-t/(math.log(p, 2)))\n",
    "# lang = '%s->%s' % (row['ui_language'], row['learning_language'])\n",
    "# lexeme_id = row['lexeme_id']\n",
    "# lexeme_string = row['lexeme_string']\n",
    "# timestamp = int(row['timestamp'])\n",
    "# user_id = row['user_id']\n",
    "# seen = int(row['history_seen'])\n",
    "# right = int(row['history_correct'])\n",
    "# wrong = seen - right\n",
    "# right_this = int(row['session_correct'])\n",
    "# wrong_this = int(row['session_seen']) - right_this\n",
    "\n",
    "# they left only lang combination \n",
    "# used lexeme id \n",
    "# used timestamp and lexeme_string and user_id \n",
    "# h = hclip(-t/(math.log(p, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "048b24b5-7d04-4e01-b8a1-09edada44b21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>delta</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>h_recall</th>\n",
       "      <th>word_len</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>lang_combination</th>\n",
       "      <th>avg_delta</th>\n",
       "      <th>std_delta</th>\n",
       "      <th>avg_h_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999900</td>\n",
       "      <td>5.143600</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>111241.0</td>\n",
       "      <td>en-es</td>\n",
       "      <td>2.475405e+06</td>\n",
       "      <td>2.879771e+06</td>\n",
       "      <td>0.954897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>5</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>en-de</td>\n",
       "      <td>3.104417e+03</td>\n",
       "      <td>2.977079e+03</td>\n",
       "      <td>0.890225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>3</td>\n",
       "      <td>2484854.0</td>\n",
       "      <td>en-de</td>\n",
       "      <td>3.104417e+03</td>\n",
       "      <td>2.977079e+03</td>\n",
       "      <td>0.890225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>4</td>\n",
       "      <td>222707.0</td>\n",
       "      <td>en-de</td>\n",
       "      <td>3.104417e+03</td>\n",
       "      <td>2.977079e+03</td>\n",
       "      <td>0.890225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "      <td>143725.0</td>\n",
       "      <td>en-de</td>\n",
       "      <td>3.104417e+03</td>\n",
       "      <td>2.977079e+03</td>\n",
       "      <td>0.890225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12509996</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>3</td>\n",
       "      <td>22761659.0</td>\n",
       "      <td>it-en</td>\n",
       "      <td>5.391088e+04</td>\n",
       "      <td>6.550006e+04</td>\n",
       "      <td>0.892502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12509997</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>197654.0</td>\n",
       "      <td>it-en</td>\n",
       "      <td>5.391088e+04</td>\n",
       "      <td>6.550006e+04</td>\n",
       "      <td>0.892502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12509998</th>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>24828.0</td>\n",
       "      <td>it-en</td>\n",
       "      <td>5.391088e+04</td>\n",
       "      <td>6.550006e+04</td>\n",
       "      <td>0.892502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12509999</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>182580.0</td>\n",
       "      <td>it-en</td>\n",
       "      <td>5.391088e+04</td>\n",
       "      <td>6.550006e+04</td>\n",
       "      <td>0.892502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12510000</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>5</td>\n",
       "      <td>193014.0</td>\n",
       "      <td>it-en</td>\n",
       "      <td>5.391088e+04</td>\n",
       "      <td>6.550006e+04</td>\n",
       "      <td>0.892502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12505498 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_recall     delta  history_seen  history_correct  h_recall  \\\n",
       "0         0.999900  5.143600             3                3  1.000000   \n",
       "1         0.999900  0.069016             8                6  0.750000   \n",
       "2         0.750000  0.069016             6                5  0.833333   \n",
       "3         0.888889  0.069016             6                5  0.833333   \n",
       "4         0.800000  0.069016             8                6  0.750000   \n",
       "...            ...       ...           ...              ...       ...   \n",
       "12509996  0.800000  0.004259             6                4  0.666667   \n",
       "12509997  0.800000  0.004259             4                4  1.000000   \n",
       "12509998  0.999900  0.004259             4                4  1.000000   \n",
       "12509999  0.600000  0.004259             3                2  0.666667   \n",
       "12510000  0.666667  0.004259             5                3  0.600000   \n",
       "\n",
       "          word_len     SUBTLEX lang_combination     avg_delta     std_delta  \\\n",
       "0                4    111241.0            en-es  2.475405e+06  2.879771e+06   \n",
       "1                5      3391.0            en-de  3.104417e+03  2.977079e+03   \n",
       "2                3   2484854.0            en-de  3.104417e+03  2.977079e+03   \n",
       "3                4    222707.0            en-de  3.104417e+03  2.977079e+03   \n",
       "4                4    143725.0            en-de  3.104417e+03  2.977079e+03   \n",
       "...            ...         ...              ...           ...           ...   \n",
       "12509996         3  22761659.0            it-en  5.391088e+04  6.550006e+04   \n",
       "12509997         3    197654.0            it-en  5.391088e+04  6.550006e+04   \n",
       "12509998         5     24828.0            it-en  5.391088e+04  6.550006e+04   \n",
       "12509999         5    182580.0            it-en  5.391088e+04  6.550006e+04   \n",
       "12510000         5    193014.0            it-en  5.391088e+04  6.550006e+04   \n",
       "\n",
       "          avg_h_recall  \n",
       "0             0.954897  \n",
       "1             0.890225  \n",
       "2             0.890225  \n",
       "3             0.890225  \n",
       "4             0.890225  \n",
       "...                ...  \n",
       "12509996      0.892502  \n",
       "12509997      0.892502  \n",
       "12509998      0.892502  \n",
       "12509999      0.892502  \n",
       "12510000      0.892502  \n",
       "\n",
       "[12505498 rows x 11 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a9c23870-3c10-4802-8d52-46d996be04c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m fv\u001b[38;5;241m.\u001b[39mappend((intern(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_h_recall\u001b[39m\u001b[38;5;124m'\u001b[39m), dff_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg_h_recall\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# fv.append((intern('tags_list'), tags_list))\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m instances\u001b[38;5;241m.\u001b[39mappend(Instance(\u001b[43mp\u001b[49m, t, fv, h))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "# datanstance object\n",
    "instances = list()\n",
    "Instance = namedtuple('Instance', 'p_recall delta fv half_life'.split())\n",
    "\n",
    "# feature vector is a list of (feature, value) tuples\n",
    "fv = []\n",
    "fv.append((intern('history_seen'), np.sqrt(1+dff_final['history_seen'])))\n",
    "fv.append((intern('history_correct'), np.sqrt(1+dff_final['history_correct'])))\n",
    "fv.append((intern('h_recall'), dff_final['h_recall']))\n",
    "fv.append((intern('word_len'), dff_final['word_len']))\n",
    "fv.append((intern('SUBTLEX'), dff_final['SUBTLEX']))\n",
    "fv.append((intern('lang_comb'), dff_final['lang_combination']))\n",
    "fv.append((intern('avg_delta'), dff_final['avg_delta']))\n",
    "fv.append((intern('SUBTLEX'), dff_final['SUBTLEX']))\n",
    "fv.append((intern('std_delta'), dff_final['std_delta']))\n",
    "fv.append((intern('avg_h_recall'), dff_final['avg_h_recall']))\n",
    "# fv.append((intern('tags_list'), tags_list))\n",
    "\n",
    "instances.append(Instance(p, t, fv, h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4115b8d2-8cbd-44a0-ba22-99f2b2239bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the Instance namedtuple\n",
    "Instance = namedtuple('Instance', 'p_recall delta fv half_life')\n",
    "\n",
    "# Function to transform a DataFrame row into an Instance object\n",
    "def create_instances_from_dataframe(df):\n",
    "    instances = []\n",
    "    for _, row in df.iterrows():\n",
    "        # Build the feature vector for this row\n",
    "        fv = []\n",
    "        fv.append((intern('history_seen'), np.sqrt(1 + row['history_seen'])))\n",
    "        fv.append((intern('history_correct'), np.sqrt(1 + row['history_correct'])))\n",
    "        fv.append((intern('h_recall'), row['h_recall']))\n",
    "        fv.append((intern('word_len'), row['word_len']))\n",
    "        fv.append((intern('SUBTLEX'), row['SUBTLEX']))\n",
    "        fv.append((intern('lang_comb'), row['lang_combination']))\n",
    "        fv.append((intern('avg_delta'), row['avg_delta']))\n",
    "        fv.append((intern('SUBTLEX'), row['SUBTLEX']))\n",
    "        fv.append((intern('std_delta'), row['std_delta']))\n",
    "        fv.append((intern('avg_h_recall'), row['avg_h_recall']))\n",
    "        # You can add other features as necessary\n",
    "\n",
    "        # Create the Instance object\n",
    "        instance = Instance(\n",
    "            p_recall=row['p_recall'],\n",
    "            delta=row['delta'],\n",
    "            fv=fv,\n",
    "            half_life=row['half_life']\n",
    "        )\n",
    "\n",
    "        # Append to the list of instances\n",
    "        instances.append(instance)\n",
    "    \n",
    "    return instances\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c41c7b25-134a-49c2-8b8b-d775b192ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "min_half_life = 15.0 / (24 * 60)  # 15 minutes in days\n",
    "max_half_life = 274.0            # 9 months\n",
    "LN2 = math.log(2)\n",
    "\n",
    "# Utility functions\n",
    "def pclip(p):\n",
    "    \"\"\"Clip recall probability to avoid numerical issues.\"\"\"\n",
    "    return np.clip(p, 0.001, 0.9999)\n",
    "\n",
    "def hclip(h):\n",
    "    \"\"\"Clip half-life to a reasonable range.\"\"\"\n",
    "    return np.clip(h, min_half_life, max_half_life)\n",
    "\n",
    "def mae(l1, l2):\n",
    "    # mean average error\n",
    "    return mean([abs(l1[i] - l2[i]) for i in range(len(l1))])\n",
    "\n",
    "def mean(lst):\n",
    "    # the average of a list\n",
    "    return float(sum(lst))/len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893839da-8b8f-4e19-8b8c-4bbbdeb4499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the HLR Model\n",
    "class HalfLifeRegression:\n",
    "    def __init__(self, learning_rate=0.001, hlwt=0.01, l2wt=0.1, sigma=1.):\n",
    "        self.weights = defaultdict(float)  # Feature weights\n",
    "        self.fcounts = defaultdict(int)    # Feature counts for adaptive learning rates\n",
    "        self.learning_rate = learning_rate # Base learning rate\n",
    "        self.hlwt = hlwt                   # Weight for half-life loss\n",
    "        self.l2wt = l2wt                   # L2 regularization weight\n",
    "        self.sigma = sigma\n",
    "        if initial_weights is not None:\n",
    "            self.weights.update(initial_weights)\n",
    "\n",
    "    def halflife(self, inst):\n",
    "        \"\"\"Compute predicted half-life based on feature vector.\"\"\"\n",
    "        try:\n",
    "            dp = sum([self.weights[k]*x_k for (k, x_k) in inst.fv]) # where inst.fv  is the feature vector\n",
    "            return hclip(2 ** dp)\n",
    "        except: \n",
    "            return MAX_HALF_LIFE\n",
    "            \n",
    "\n",
    "    def predict(self, inst):\n",
    "        \"\"\"Predict recall probability and half-life.\"\"\"\n",
    "        h_pred = self.halflife(inst)\n",
    "        p_pred = 2 ** (-inst.delta / h) \n",
    "        return pclip(p_pred), h_pred\n",
    "\n",
    "                \n",
    "     def train_update(self, inst):\n",
    "        \"\"\"Update weights using one training instance.\"\"\"\n",
    "        p_pred, h_pred = self.predict(inst)\n",
    "\n",
    "        # Compute gradients\n",
    "        dlp_dw = 2*(p_pred - inst.p_recall)*(LN2 ** 2)*p_pred*(inst.delta/h_pred)\n",
    "        dlh_dw = 2*(h_pred - inst.half_life)*LN2*h_pred\n",
    "\n",
    "        # Update weights\n",
    "        for (k, x_k) in inst.fv:\n",
    "            rate = (1./(1+inst.p_recall)) * self.lrate / math.sqrt(1 + self.fcounts[k])\n",
    "            self.weights[k] -= rate * dlp_dw * x_k  # Update for recall probability loss\n",
    "            self.weights[k] -= rate * self.hlwt * dlh_dw * x_k  # Update for half-life loss\n",
    "            self.weights[k] -= rate * self.l2wt * self.weights[k] / self.sigma**2  # L2 regularization\n",
    "            self.fcounts[k] += 1\n",
    "\n",
    "\n",
    "    def train(self, trainset):\n",
    "        random.shuffle(trainset)\n",
    "        for instance in trainset:\n",
    "            self.train_update(inst)\n",
    "\n",
    "    def evaluate(self, testset):\n",
    "        \"\"\"Evaluate the model on a test dataset.\"\"\"\n",
    "        results = {'p': [], 'h': [], 'pp': [], 'hh': [], 'slp': [], 'slh': []}\n",
    "        for instance in testset:\n",
    "            slp, slh, p, h = self.losses(inst)\n",
    "            results['p'].append(inst.p_recall)     # ground truth\n",
    "            results['h'].append(inst.h_recall)\n",
    "            results['pp'].append(p_pred)         # predictions\n",
    "            results['hh'].append(h_pred)\n",
    "            results['slp'].append(slp)      # loss function values\n",
    "            results['slh'].append(slh)\n",
    "            mae_p = mae(results['p'], results['pp'])\n",
    "            mae_h = mae(results['h'], results['hh'])\n",
    "            total_slp = sum(results['slp'])\n",
    "            total_slh = sum(results['slh'])\n",
    "            total_l2 = sum([x**2 for x in self.weights.values()])\n",
    "            total_loss = total_slp + self.hlwt*total_slh + self.l2wt*total_l2\n",
    "        print(f\"SLP Loss: {total_slp}, SLH Loss: {total_slh}, MAE_P: {mae_p}, MAE_H: {mae_h}, total loss {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42723394-33b0-4a81-9615-d8a8941a7407",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HalfLifeRegression()\n",
    "model.train(trainset)\n",
    "model.evaluate(testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

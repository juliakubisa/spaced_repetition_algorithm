{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c735b02c-eeab-417e-892c-1d02851886cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer, OneHotEncoder, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5a559aaf-d957-45e2-8b9b-c91f41ea2c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['timestamp', 'lexeme_id', 'word', 'user_id', 'session_seen', 'session_correct', 'avg_user_p_recall']\n",
    "current_dir = os.getcwd()\n",
    "filename = 'df_processed.csv'\n",
    "filepath = os.path.normpath(os.path.join(current_dir, '../data/processed/', filename))\n",
    "\n",
    "chunk_size = 10000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(filepath, chunksize=chunk_size):\n",
    "    chunk.drop_duplicates(inplace=True)\n",
    "    chunk.dropna(inplace=True)\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "df_users = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../data/features/', 'users_behaviur.csv')))\n",
    "df_words = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../data/features/', 'word_complexity_features.csv')), sep='\\t')\n",
    "dff = pd.merge(pd.merge(df_words, df, on = 'lexeme_id', how='inner'), df_users, on = ['user_id', 'lang_combination'], how='inner')\n",
    "dff.drop(columns=cols_to_drop, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fc93f230-ce9b-4a81-b9bd-b626683733a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['p_recall', 'delta', 'learning_language', 'ui_language', 'history_seen',\n",
       "       'history_correct', 'h_recall', 'lang_combination', 'gender', 'def',\n",
       "       'tense', 'POS', 'person', 'number', 'word_len', 'tags_list', 'SUBTLEX',\n",
       "       'avg_delta', 'std_delta', 'avg_h_recall'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b9ac800-5694-40f9-a09f-efa1bf6edc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle tags \n",
    "# 1) Store tags as list, but delete rows where there are less than x occurences \n",
    "dff_1 = dff.copy()\n",
    "tag_counts = dff_1['tags_list'].value_counts()\n",
    "rare_threshold = 1000\n",
    "dff_1['tags_list'] = dff_1['tags_list'].apply(lambda x: x if tag_counts[x] > rare_threshold else 'rare')\n",
    "\n",
    "dff_1.drop(columns=['POS', 'person', 'number', 'gender', 'tense', 'def'], inplace=True)\n",
    "dff_1.dropna(inplace=True)\n",
    "\n",
    "# 2) Store each tag as column, replace NaN values with a placeholder for categorical columns\n",
    "# categorical_cols = dff.select_dtypes(include=['object']).columns.tolist()\n",
    "# dff_2 = dff.copy()\n",
    "# dff_2[categorical_cols] = dff_2[categorical_cols].fillna('missing')\n",
    "# dff_2.drop(columns=['tags_list'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf972f7-8e20-434e-832d-83cc297ac30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF -> iteratevily delete columns that had VIF > 10\n",
    "def calculate_vif(X):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "    return vif_data\n",
    "    \n",
    "dff_VIF = dff_1.drop(columns=['p_recall', 'avg_h_recall', 'history_correct']).sample(2000000)\n",
    "vif = calculate_vif(dff_VIF.select_dtypes(exclude='O'))\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50f3a2f-57ab-4426-8bb4-af7204853577",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_features = [\"avg_h_recall\", \"avg_user_p_recall\", 'history_correct']\n",
    "correlation_with_target = dff_1[removed_features + [\"p_recall\"]].corr()[\"p_recall\"]\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b0035124-cf14-4b2e-90b7-4e63f501e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_final = dff_1\n",
    "# dff_final = dff_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "47a62146-3a0b-4a0b-97e0-0d04113656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming skewed variables\n",
    "dff_final['history_wrong'] = np.log(1+(dff_final['history_seen']-dff_final['history_correct']))\n",
    "dff_final['delta'] = np.log(dff_final['delta']/(60*60*24))\n",
    "dff_final['avg_delta'] = np.log(dff_final['avg_delta']/(60*60*24))\n",
    "dff_final['history_seen'] = np.log(1+dff_final['history_seen'])\n",
    "dff_final['history_correct'] = np.log(1+dff_final['history_correct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "d081b9b2-7200-4145-a885-c39971c1a03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation of target variable \n",
    "\n",
    "# Logit transformation \n",
    "def logit_transform(y, epsilon=1e-10):\n",
    "    y = np.clip(y, epsilon, 1 - epsilon)\n",
    "    return np.log(y / (1 - y))\n",
    "\n",
    "def inverse_logit_transform(y):\n",
    "    return 1 / (1 + np.exp(-y))\n",
    "\n",
    "\n",
    "# Log transformation \n",
    "def log_transform(y, epsilon=1e-10):\n",
    "    return np.log(y + epsilon)\n",
    "\n",
    "def inverse_log_transform(y):\n",
    "    return np.exp(y)\n",
    "\n",
    "\n",
    "# Box-Cox transformation\n",
    "power_transformer = PowerTransformer(method='box-cox', standardize=False)\n",
    "def power_transform(y, epsilon=1e-10):\n",
    "    return power_transformer.fit_transform(y+epsilon) \n",
    "\n",
    "def inverse_power_transform(y, epsilon=1e-10):\n",
    "    return power_transformer.inverse_transform(y+epsilon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "30999554-179f-4380-bd14-808e19634955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create df without word features \n",
    "dff_t = dff_final.drop(columns=['tags_list', 'word_len', 'SUBTLEX'], errors='ignore')\n",
    "\n",
    "# DF original \n",
    "dff_s = dff_final.drop(columns=['SUBTLEX', 'tags_list', 'word_len', 'avg_delta', 'std_delta', 'avg_h_recall', 'lang_combination', 'h_recall'], errors='ignore')\n",
    "\n",
    "# DF without user columns \n",
    "dff_u = dff_final.drop(columns=['avg_delta', 'std_delta', 'avg_h_recall', 'h_recall'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "6faebfda-81e3-4416-8387-954f4885899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe(df):\n",
    "    \"\"\"\n",
    "    One-hot encode categorical variables\n",
    "    \"\"\" \n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    ohe = OneHotEncoder(sparse_output=False)\n",
    "    ohe_data = ohe.fit_transform(df[categorical_cols])\n",
    "    ohe_df = pd.DataFrame(ohe_data, columns=ohe.get_feature_names_out(categorical_cols))\n",
    "    df_encoded = pd.concat([df.select_dtypes(exclude='O'), ohe_df], axis=1)\n",
    "    df_encoded.dropna(inplace=True)\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "c5e7538c-7f93-403e-8f9a-4790989e8ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df):\n",
    "    X = df.drop(columns='p_recall')\n",
    "    y = df['p_recall']\n",
    "    X_train, X_test, y_train, y_test = sklearn_train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        train_size=0.8,\n",
    "                                                        random_state=42)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "78b2c4d4-1f08-4dab-a413-d2aa8e9d603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cap_y(prediction): \n",
    "    return np.clip(prediction, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "81b114ed-a5df-40f2-8c02-8acce707ccc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_encoded = ohe(dff_final)\n",
    "dff_t_encoded = ohe(dff_t)\n",
    "dff_s_encoded = ohe(dff_s)\n",
    "dff_u_encoded = ohe(dff_u)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_dataset(dff_encoded)\n",
    "X_train_t, X_test_t, y_train_t, y_test_t = split_dataset(dff_t_encoded)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = split_dataset(dff_s_encoded)\n",
    "X_train_u, X_test_u, y_train_u, y_test_u = split_dataset(dff_u_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "ab97e5ba-151d-4e3a-a7fd-b719e6c67e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(model_type=\"linear\", alpha=1.0, **kwargs):\n",
    "    \"\"\"\n",
    "    Create a pipeline for regression with optional feature selection.\n",
    "    \n",
    "    Returns:\n",
    "    - Pipeline object\n",
    "    \"\"\"\n",
    "    if model_type == \"ridge\":\n",
    "        model = Ridge(alpha=alpha, fit_intercept=True)\n",
    "    else:\n",
    "        model = LinearRegression()\n",
    "\n",
    "    steps = [\n",
    "        ('scaler', StandardScaler()),\n",
    "        # ('polynomial_features', PolynomialFeatures(degree=3, include_bias=False)),\n",
    "        ('model', model)\n",
    "        # ('model', TransformedTargetRegressor(regressor=model, \n",
    "        #                                     func=log_transform,\n",
    "        #                                     inverse_func=inverse_log_transform))\n",
    "    ]\n",
    "    return Pipeline(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "e6d6b701-7bb4-4efb-afac-228e18a6ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test, name=\"Model\"):\n",
    "    \"\"\"\n",
    "    Train and evaluate a pipeline, returning metrics.\n",
    "    \"\"\"\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    # Predict on both train and test\n",
    "    y_train_pred = cap_y(pipeline.predict(X_train))\n",
    "    y_test_pred = cap_y(pipeline.predict(X_test)) \n",
    "\n",
    "    # Calculate metrics \n",
    "    train_r2 = r2_score(y_train, y_train_pred)\n",
    "    test_r2 = r2_score(y_test, y_test_pred)\n",
    "    test_mae = mean_absolute_error(y_test, y_test_pred)\n",
    "    train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "    \n",
    "    print(f\"{name}: Train R2 = {round(train_r2, 4)}, Test R2 = {round(test_r2,4)}, Train MAE = {round(train_mae,4)}, Test MAE = {round(test_mae, 4)}\")\n",
    "    return y_train_pred, y_test_pred, test_mae, test_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "93f81ffd-92da-4595-9ba4-22293ec0ef0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Configurations for Pipelines\n",
    "pipelines_config = [\n",
    "    {\"name\": \"Linear Regression\", \"model_type\": \"linear\"}\n",
    "    # {\"name\": \"Ridge Regression\", \"model_type\": \"ridge\", \"alpha\": 100},\n",
    "    # {\"name\": \"Lasso Regression\", \"model_type\": \"lasso\"},\n",
    "]\n",
    "\n",
    "def regression_results(pipelines_config, X_train, X_test, y_train, y_test, importance='No'):\n",
    "    results = []\n",
    "    importances = [] \n",
    "    \n",
    "    for config in pipelines_config:\n",
    "        pipeline = create_pipeline(**config)\n",
    "        y_train_pred, y_test_pred, mae, r2 = evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test, name=config[\"name\"])\n",
    "        results.append((config[\"name\"], mae, r2))\n",
    "\n",
    "        if isinstance(importance, str) and importance == 'Yes':\n",
    "            model = pipeline.named_steps[\"model\"]\n",
    "            importance = model.coef_\n",
    "            importances.append((config[\"name\"], X_train.columns, importance))\n",
    "\n",
    "    importance_df = pd.DataFrame(importances, columns = ['Model', 'Feature', 'Importance'])\n",
    "    results_df = pd.DataFrame(results, columns=['Model', 'Test MAE', 'Test R2'])   \n",
    "\n",
    "    full_df = X_test.copy()\n",
    "    full_df['predictions'] = y_test_pred\n",
    "    full_df['p_recall'] = y_test\n",
    "\n",
    "    return results_df, importance_df, full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "b5c939dd-6686-4646-812b-51b164d4cc7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for all features\n",
      "Linear Regression: Train R2 = 0.0343, Test R2 = 0.0338, Train MAE = 0.166, Test MAE = 0.1662\n",
      "Results after deleting word features\n",
      "Linear Regression: Train R2 = 0.0342, Test R2 = 0.0338, Train MAE = 0.1661, Test MAE = 0.1663\n",
      "Results without word and user features\n",
      "Linear Regression: Train R2 = 0.016, Test R2 = 0.0158, Train MAE = 0.1691, Test MAE = 0.1694\n",
      "Results without user features\n",
      "Linear Regression: Train R2 = 0.0163, Test R2 = 0.0159, Train MAE = 0.169, Test MAE = 0.1693\n"
     ]
    }
   ],
   "source": [
    "print('Results for all features')\n",
    "results_all, importance_all, full_df_all = regression_results(pipelines_config, X_train, X_test, y_train, y_test, importance='No')\n",
    "\n",
    "print('Results after deleting word features')\n",
    "results_t, importance_t, full_df_t = regression_results(pipelines_config, X_train_t, X_test_t, y_train_t, y_test_t, importance='Yes')\n",
    "\n",
    "print('Results without word and user features')\n",
    "results_s, importance_s, full_df_s  = regression_results(pipelines_config, X_train_s, X_test_s, y_train_s, y_test_s, importance='Yes')\n",
    "\n",
    "print('Results without user features') \n",
    "results_u, importance_u, full_df_u = regression_results(pipelines_config, X_train_u, X_test_u, y_train_u, y_test_u, importance='No')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e5e8b9-eecf-4b22-b322-9db2bbe4be82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "25eab286-611e-4545-8d2e-a81c99b7d3d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>history_seen</td>\n",
       "      <td>-0.363156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>h_recall</td>\n",
       "      <td>-0.043682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>history_wrong</td>\n",
       "      <td>-0.014109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>delta</td>\n",
       "      <td>-0.0089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>std_delta</td>\n",
       "      <td>-0.004078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>avg_delta</td>\n",
       "      <td>-0.002885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>ui_language_it</td>\n",
       "      <td>-0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_it-en</td>\n",
       "      <td>-0.000124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>ui_language_es</td>\n",
       "      <td>-0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_es-en</td>\n",
       "      <td>-0.000068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>learning_language_es</td>\n",
       "      <td>-0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_en-es</td>\n",
       "      <td>-0.000057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_en-de</td>\n",
       "      <td>-0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>learning_language_de</td>\n",
       "      <td>-0.000055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>learning_language_en</td>\n",
       "      <td>-0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>ui_language_en</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_en-fr</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>learning_language_fr</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_en-pt</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>learning_language_pt</td>\n",
       "      <td>0.000065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_en-it</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>learning_language_it</td>\n",
       "      <td>0.000111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>lang_combination_pt-en</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>ui_language_pt</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>avg_h_recall</td>\n",
       "      <td>0.037459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear Regression</td>\n",
       "      <td>history_correct</td>\n",
       "      <td>0.373101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model                 Feature Importance\n",
       "1   Linear Regression            history_seen  -0.363156\n",
       "3   Linear Regression                h_recall  -0.043682\n",
       "7   Linear Regression           history_wrong  -0.014109\n",
       "0   Linear Regression                   delta    -0.0089\n",
       "5   Linear Regression               std_delta  -0.004078\n",
       "4   Linear Regression               avg_delta  -0.002885\n",
       "16  Linear Regression          ui_language_it  -0.000124\n",
       "24  Linear Regression  lang_combination_it-en  -0.000124\n",
       "15  Linear Regression          ui_language_es  -0.000068\n",
       "23  Linear Regression  lang_combination_es-en  -0.000068\n",
       "10  Linear Regression    learning_language_es  -0.000057\n",
       "19  Linear Regression  lang_combination_en-es  -0.000057\n",
       "18  Linear Regression  lang_combination_en-de  -0.000055\n",
       "8   Linear Regression    learning_language_de  -0.000055\n",
       "9   Linear Regression    learning_language_en  -0.000006\n",
       "14  Linear Regression          ui_language_en   0.000006\n",
       "20  Linear Regression  lang_combination_en-fr   0.000025\n",
       "11  Linear Regression    learning_language_fr   0.000025\n",
       "22  Linear Regression  lang_combination_en-pt   0.000065\n",
       "13  Linear Regression    learning_language_pt   0.000065\n",
       "21  Linear Regression  lang_combination_en-it   0.000111\n",
       "12  Linear Regression    learning_language_it   0.000111\n",
       "25  Linear Regression  lang_combination_pt-en   0.000191\n",
       "17  Linear Regression          ui_language_pt   0.000191\n",
       "6   Linear Regression            avg_h_recall   0.037459\n",
       "2   Linear Regression         history_correct   0.373101"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze coefficients\n",
    "importance_tt = importance_t.explode([\"Feature\", \"Importance\"]).reset_index(drop=True)\n",
    "importance_tt.sort_values(by='Importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "0f1c96c5-8e26-4389-8906-98bd0fd43e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze \n",
    "full_df_all['diff'] = full_df_all['p_recall'] - full_df_all['predictions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "d36f2cd0-e716-40a0-91bc-609131a21af0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>delta</th>\n",
       "      <th>h_recall</th>\n",
       "      <th>word_len</th>\n",
       "      <th>p_recall</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2321052</th>\n",
       "      <td>2368.0</td>\n",
       "      <td>-5.264184</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802634</th>\n",
       "      <td>72685.0</td>\n",
       "      <td>-6.522556</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2186015</th>\n",
       "      <td>657.0</td>\n",
       "      <td>-5.132332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614993</th>\n",
       "      <td>139131.0</td>\n",
       "      <td>-6.225079</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1470645</th>\n",
       "      <td>17773.0</td>\n",
       "      <td>-6.162736</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194053</th>\n",
       "      <td>197654.0</td>\n",
       "      <td>-0.338975</td>\n",
       "      <td>0.275591</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.383890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332305</th>\n",
       "      <td>2711.0</td>\n",
       "      <td>3.620595</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.376071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3260655</th>\n",
       "      <td>7251.0</td>\n",
       "      <td>0.839460</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.363640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3833667</th>\n",
       "      <td>444863.0</td>\n",
       "      <td>-0.488658</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.328626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232666</th>\n",
       "      <td>2925411.0</td>\n",
       "      <td>0.202081</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316285</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>399516 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           SUBTLEX     delta  h_recall  word_len  p_recall  predictions\n",
       "2321052     2368.0 -5.264184  1.000000       8.0       0.0     1.000000\n",
       "4802634    72685.0 -6.522556  1.000000       7.0       0.0     1.000000\n",
       "2186015      657.0 -5.132332  1.000000      10.0       0.0     1.000000\n",
       "1614993   139131.0 -6.225079  1.000000       6.0       0.0     1.000000\n",
       "1470645    17773.0 -6.162736  1.000000       5.0       0.0     1.000000\n",
       "...            ...       ...       ...       ...       ...          ...\n",
       "194053    197654.0 -0.338975  0.275591       3.0       1.0     0.383890\n",
       "3332305     2711.0  3.620595  0.166667       9.0       1.0     0.376071\n",
       "3260655     7251.0  0.839460  0.300000       7.0       1.0     0.363640\n",
       "3833667   444863.0 -0.488658  0.250000       5.0       1.0     0.328626\n",
       "232666   2925411.0  0.202081  0.111111       2.0       1.0     0.316285\n",
       "\n",
       "[399516 rows x 6 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df_all.sort_values('diff')[['SUBTLEX', 'delta', 'h_recall', 'word_len', 'p_recall', 'predictions']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a7f9ea1-66c1-443f-ab8f-a7afb7bc0e32",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfull_df_all\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_df_all' is not defined"
     ]
    }
   ],
   "source": [
    "full_df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "a4390217-b44b-481b-8e64-3683dfce7472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test MSE Plot\n",
    "plt.subplot(4, 1, 4)\n",
    "# plt.bar(results_t['Test MAE'])\n",
    "plt.bar(results_all['Test MAE'],color='skyblue')\n",
    "plt.title('Test MSE Comparison')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a174dcc4-149b-46b8-b4d6-ba756ccafd78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if residuals are normally distributed \n",
    "sns.distplot((y_test-y_pred_capped),bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d158dfe-86d3-467a-817f-a4d266813c1b",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

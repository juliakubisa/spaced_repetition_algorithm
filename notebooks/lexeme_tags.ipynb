{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "# Original Dataset \n",
    "filename = '13 million Duolingo student learning traces.csv'\n",
    "filepath = os.path.normpath(os.path.join(current_dir, '../data/raw/', filename))\n",
    "\n",
    "\n",
    "chunk_size = 10000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(filepath, chunksize=chunk_size):\n",
    "    chunk.drop_duplicates(inplace=True)\n",
    "    chunk.dropna(inplace=True)\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>76390c1350a8dac31186187e2fe1e178</td>\n",
       "      <td>lernt/lernen&lt;vblex&gt;&lt;pri&gt;&lt;p3&gt;&lt;sg&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>7dfd7086f3671685e2cf1c1da72796d7</td>\n",
       "      <td>die/die&lt;det&gt;&lt;def&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>35a54c25a2cda8127343f6a82e6f6b7d</td>\n",
       "      <td>mann/mann&lt;n&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>0cf63ffe3dda158bc3dbd55682b355ae</td>\n",
       "      <td>frau/frau&lt;n&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>84920990d78044db53c1b012f5bf9ab5</td>\n",
       "      <td>das/das&lt;det&gt;&lt;def&gt;&lt;nt&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854140</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1363104897</td>\n",
       "      <td>368</td>\n",
       "      <td>u:i5D8</td>\n",
       "      <td>en</td>\n",
       "      <td>it</td>\n",
       "      <td>d5efc552aaea3109eb5388aa1ec8673d</td>\n",
       "      <td>the/the&lt;det&gt;&lt;def&gt;&lt;sp&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854141</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>1363104897</td>\n",
       "      <td>368</td>\n",
       "      <td>u:i5D8</td>\n",
       "      <td>en</td>\n",
       "      <td>it</td>\n",
       "      <td>a826c47947d68549fa81e19cafa57ba0</td>\n",
       "      <td>eat/eat&lt;vblex&gt;&lt;pres&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854142</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1363104897</td>\n",
       "      <td>368</td>\n",
       "      <td>u:i5D8</td>\n",
       "      <td>en</td>\n",
       "      <td>it</td>\n",
       "      <td>5e29d77697d23070a1fb92eb6c90e9b6</td>\n",
       "      <td>bread/bread&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854143</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>1363104897</td>\n",
       "      <td>368</td>\n",
       "      <td>u:i5D8</td>\n",
       "      <td>en</td>\n",
       "      <td>it</td>\n",
       "      <td>cdfecc9247566d40bb964a218c54c783</td>\n",
       "      <td>drink/drink&lt;vblex&gt;&lt;pres&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12854144</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1363104897</td>\n",
       "      <td>368</td>\n",
       "      <td>u:i5D8</td>\n",
       "      <td>en</td>\n",
       "      <td>it</td>\n",
       "      <td>c52ab45d4e22ee7580041911159e3c0c</td>\n",
       "      <td>water/water&lt;n&gt;&lt;sg&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12854145 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_recall   timestamp     delta user_id learning_language  \\\n",
       "0         1.000000  1362076081  27649635    u:FO                de   \n",
       "1         0.500000  1362076081  27649635    u:FO                de   \n",
       "2         1.000000  1362076081  27649635    u:FO                de   \n",
       "3         0.500000  1362076081  27649635    u:FO                de   \n",
       "4         1.000000  1362076081  27649635    u:FO                de   \n",
       "...            ...         ...       ...     ...               ...   \n",
       "12854140  0.800000  1363104897       368  u:i5D8                en   \n",
       "12854141  0.800000  1363104897       368  u:i5D8                en   \n",
       "12854142  1.000000  1363104897       368  u:i5D8                en   \n",
       "12854143  0.600000  1363104897       368  u:i5D8                en   \n",
       "12854144  0.666667  1363104897       368  u:i5D8                en   \n",
       "\n",
       "         ui_language                         lexeme_id  \\\n",
       "0                 en  76390c1350a8dac31186187e2fe1e178   \n",
       "1                 en  7dfd7086f3671685e2cf1c1da72796d7   \n",
       "2                 en  35a54c25a2cda8127343f6a82e6f6b7d   \n",
       "3                 en  0cf63ffe3dda158bc3dbd55682b355ae   \n",
       "4                 en  84920990d78044db53c1b012f5bf9ab5   \n",
       "...              ...                               ...   \n",
       "12854140          it  d5efc552aaea3109eb5388aa1ec8673d   \n",
       "12854141          it  a826c47947d68549fa81e19cafa57ba0   \n",
       "12854142          it  5e29d77697d23070a1fb92eb6c90e9b6   \n",
       "12854143          it  cdfecc9247566d40bb964a218c54c783   \n",
       "12854144          it  c52ab45d4e22ee7580041911159e3c0c   \n",
       "\n",
       "                             lexeme_string  history_seen  history_correct  \\\n",
       "0         lernt/lernen<vblex><pri><p3><sg>             6                4   \n",
       "1            die/die<det><def><f><sg><nom>             4                4   \n",
       "2                 mann/mann<n><m><sg><nom>             5                4   \n",
       "3                 frau/frau<n><f><sg><nom>             6                5   \n",
       "4           das/das<det><def><nt><sg><nom>             4                4   \n",
       "...                                    ...           ...              ...   \n",
       "12854140             the/the<det><def><sp>             6                4   \n",
       "12854141              eat/eat<vblex><pres>             4                4   \n",
       "12854142                bread/bread<n><sg>             4                4   \n",
       "12854143          drink/drink<vblex><pres>             3                2   \n",
       "12854144                water/water<n><sg>             5                3   \n",
       "\n",
       "          session_seen  session_correct  \n",
       "0                    2                2  \n",
       "1                    2                1  \n",
       "2                    1                1  \n",
       "3                    2                1  \n",
       "4                    1                1  \n",
       "...                ...              ...  \n",
       "12854140             5                4  \n",
       "12854141             5                4  \n",
       "12854142             4                4  \n",
       "12854143             5                3  \n",
       "12854144             9                6  \n",
       "\n",
       "[12854145 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPOTHESIS 1 \n",
    "\"\"\" Instead of the sparse indicator variables used here, it may be better to decompose lexeme tags \n",
    "into denser and more generic features of tag components (e.g., part of speech, tense, gender, case), \n",
    "and also use corpus frequency, word length, etc.\"\"\"\n",
    "lexeme_filepath = os.path.normpath(os.path.join(current_dir, '../data/', 'lexeme_reference.csv'))\n",
    "lexeme_reference = pd.read_csv(lexeme_filepath, sep = ';', header=None, on_bad_lines='warn', \n",
    "                               names=[\"tag\", \"type\", \"description\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adjective</th>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animacy</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>def</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>propernoun</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tense</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            tag  description\n",
       "type                        \n",
       "POS          22           22\n",
       "adjective    18           18\n",
       "animacy       3            3\n",
       "case          2            2\n",
       "def           2            2\n",
       "gender        5            5\n",
       "number        4            4\n",
       "other        14           14\n",
       "person        3            3\n",
       "propernoun    2            2\n",
       "tense        17           17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes_grouped = lexeme_reference.groupby('type')\n",
    "lexemes_grouped.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_tags_reference(df): \n",
    "    df = df[df[\"type\"].str.contains(\"adjective|animacy|other|propernoun|case\") == False]\n",
    "    tags_dict = df.set_index('tag')['type'].to_dict()\n",
    "    types = set(tags_dict.values())\n",
    "    return tags_dict, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_dict, types = prepare_tags_reference(lexeme_reference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lexeme_type in types:\n",
    "    df[lexeme_type] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>delta</th>\n",
       "      <th>user_id</th>\n",
       "      <th>learning_language</th>\n",
       "      <th>ui_language</th>\n",
       "      <th>lexeme_id</th>\n",
       "      <th>lexeme_string</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>session_seen</th>\n",
       "      <th>session_correct</th>\n",
       "      <th>POS</th>\n",
       "      <th>person</th>\n",
       "      <th>def</th>\n",
       "      <th>tense</th>\n",
       "      <th>gender</th>\n",
       "      <th>number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>76390c1350a8dac31186187e2fe1e178</td>\n",
       "      <td>lernt/lernen&lt;vblex&gt;&lt;pri&gt;&lt;p3&gt;&lt;sg&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>7dfd7086f3671685e2cf1c1da72796d7</td>\n",
       "      <td>die/die&lt;det&gt;&lt;def&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>35a54c25a2cda8127343f6a82e6f6b7d</td>\n",
       "      <td>mann/mann&lt;n&gt;&lt;m&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>0cf63ffe3dda158bc3dbd55682b355ae</td>\n",
       "      <td>frau/frau&lt;n&gt;&lt;f&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362076081</td>\n",
       "      <td>27649635</td>\n",
       "      <td>u:FO</td>\n",
       "      <td>de</td>\n",
       "      <td>en</td>\n",
       "      <td>84920990d78044db53c1b012f5bf9ab5</td>\n",
       "      <td>das/das&lt;det&gt;&lt;def&gt;&lt;nt&gt;&lt;sg&gt;&lt;nom&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>228208</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>7e416735d7d43c3c0fc30d10801a352d</td>\n",
       "      <td>si/si&lt;cnjadv&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>64651</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>69faeef930a44421ec22be4b06474a06</td>\n",
       "      <td>aunque/aunque&lt;cnjadv&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>64651</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>8a100871aa249eeef95c20f864b281a1</td>\n",
       "      <td>mientras/mientras&lt;cnjadv&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>442104</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>a764900ace90aa45b2466e3cb031072e</td>\n",
       "      <td>caminas/caminar&lt;vblex&gt;&lt;pri&gt;&lt;p2&gt;&lt;sg&gt;</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1362082511</td>\n",
       "      <td>442233</td>\n",
       "      <td>u:fxGh</td>\n",
       "      <td>es</td>\n",
       "      <td>en</td>\n",
       "      <td>86584daef5933b284384453795bbf0ed</td>\n",
       "      <td>hombre/hombre&lt;n&gt;&lt;m&gt;&lt;sg&gt;</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    p_recall   timestamp     delta user_id learning_language ui_language  \\\n",
       "0   1.000000  1362076081  27649635    u:FO                de          en   \n",
       "1   0.500000  1362076081  27649635    u:FO                de          en   \n",
       "2   1.000000  1362076081  27649635    u:FO                de          en   \n",
       "3   0.500000  1362076081  27649635    u:FO                de          en   \n",
       "4   1.000000  1362076081  27649635    u:FO                de          en   \n",
       "..       ...         ...       ...     ...               ...         ...   \n",
       "95  0.666667  1362082511    228208  u:fxGh                es          en   \n",
       "96  1.000000  1362082511     64651  u:fxGh                es          en   \n",
       "97  1.000000  1362082511     64651  u:fxGh                es          en   \n",
       "98  1.000000  1362082511    442104  u:fxGh                es          en   \n",
       "99  1.000000  1362082511    442233  u:fxGh                es          en   \n",
       "\n",
       "                           lexeme_id                        lexeme_string  \\\n",
       "0   76390c1350a8dac31186187e2fe1e178     lernt/lernen<vblex><pri><p3><sg>   \n",
       "1   7dfd7086f3671685e2cf1c1da72796d7        die/die<det><def><f><sg><nom>   \n",
       "2   35a54c25a2cda8127343f6a82e6f6b7d             mann/mann<n><m><sg><nom>   \n",
       "3   0cf63ffe3dda158bc3dbd55682b355ae             frau/frau<n><f><sg><nom>   \n",
       "4   84920990d78044db53c1b012f5bf9ab5       das/das<det><def><nt><sg><nom>   \n",
       "..                               ...                                  ...   \n",
       "95  7e416735d7d43c3c0fc30d10801a352d                        si/si<cnjadv>   \n",
       "96  69faeef930a44421ec22be4b06474a06                aunque/aunque<cnjadv>   \n",
       "97  8a100871aa249eeef95c20f864b281a1            mientras/mientras<cnjadv>   \n",
       "98  a764900ace90aa45b2466e3cb031072e  caminas/caminar<vblex><pri><p2><sg>   \n",
       "99  86584daef5933b284384453795bbf0ed              hombre/hombre<n><m><sg>   \n",
       "\n",
       "    history_seen  history_correct  session_seen  session_correct   POS person  \\\n",
       "0              6                4             2                2  None   None   \n",
       "1              4                4             2                1  None   None   \n",
       "2              5                4             1                1  None   None   \n",
       "3              6                5             2                1  None   None   \n",
       "4              4                4             1                1  None   None   \n",
       "..           ...              ...           ...              ...   ...    ...   \n",
       "95             3                3             3                2  None   None   \n",
       "96             4                4             1                1  None   None   \n",
       "97             4                4             1                1  None   None   \n",
       "98             6                5             1                1  None   None   \n",
       "99            22               20             2                2  None   None   \n",
       "\n",
       "     def tense gender number  \n",
       "0   None  None   None   None  \n",
       "1   None  None   None   None  \n",
       "2   None  None   None   None  \n",
       "3   None  None   None   None  \n",
       "4   None  None   None   None  \n",
       "..   ...   ...    ...    ...  \n",
       "95  None  None   None   None  \n",
       "96  None  None   None   None  \n",
       "97  None  None   None   None  \n",
       "98  None  None   None   None  \n",
       "99  None  None   None   None  \n",
       "\n",
       "[100 rows x 18 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_from_lexemestring(lexeme_string):\n",
    "    tags = re.findall(r'<(.*?)>', lexeme_string)\n",
    "    return tags \n",
    "\n",
    "df['tags'] = df['lexeme_string'].apply(extract_from_lexemestring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_tags(tags):\n",
    "    values = {'gender': np.nan, 'POS': np.nan, 'def': np.nan, 'tense':np.nan, 'person':np.nan, 'number':np.nan}\n",
    "    for tag in tags:\n",
    "        col = tags_dict.get(tag)\n",
    "        if col and pd.isna(values[col]):  # Only assign if column is empty \n",
    "            values[col] = tag\n",
    "    return pd.Series([values['gender'], values['POS'],  values['def'], values['tense'], values['person'], values['number']])\n",
    "\n",
    "df[['gender', 'POS', 'def', 'tense', 'person', 'number']] = df['tags'].apply(assign_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New features \n",
    "df['word'] = df['lexeme_string'].str.split(\"/\").str[0]\n",
    "df['word_len'] = df['word'].apply(lambda x: len(x))\n",
    "\n",
    "# Interaction feature \n",
    "df['lang_combination'] = df['ui_language'] + '-' + df['learning_language']\n",
    "\n",
    "# Drop columns \n",
    "df.drop(columns=['tags', 'lexeme_string', 'lexeme_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lexeme = df[['learning_language', 'word', 'POS', 'person', 'def', 'tense', 'gender', 'number', 'word_len']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_b/l_819g5924d_y00npn9gt60h0000gn/T/ipykernel_88797/2171939322.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_lexeme.drop_duplicates(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df_lexeme.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_language</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>person</th>\n",
       "      <th>def</th>\n",
       "      <th>tense</th>\n",
       "      <th>gender</th>\n",
       "      <th>number</th>\n",
       "      <th>word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>de</td>\n",
       "      <td>lernt</td>\n",
       "      <td>vblex</td>\n",
       "      <td>p3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>die</td>\n",
       "      <td>det</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>sg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>de</td>\n",
       "      <td>mann</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>sg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>de</td>\n",
       "      <td>frau</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>sg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>de</td>\n",
       "      <td>das</td>\n",
       "      <td>det</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nt</td>\n",
       "      <td>sg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12818386</th>\n",
       "      <td>pt</td>\n",
       "      <td>ajuda</td>\n",
       "      <td>vblex</td>\n",
       "      <td>p3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pri</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820232</th>\n",
       "      <td>fr</td>\n",
       "      <td>conférence</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>sg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12820235</th>\n",
       "      <td>fr</td>\n",
       "      <td>liens</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>pl</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12832064</th>\n",
       "      <td>pt</td>\n",
       "      <td>foi</td>\n",
       "      <td>vblex</td>\n",
       "      <td>p3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ifi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12844224</th>\n",
       "      <td>fr</td>\n",
       "      <td>compagnie</td>\n",
       "      <td>n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>sg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12490 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         learning_language        word    POS person  def tense gender number  \\\n",
       "0                       de       lernt  vblex     p3  NaN   pri    NaN     sg   \n",
       "1                       de         die    det    NaN  def   NaN      f     sg   \n",
       "2                       de        mann      n    NaN  NaN   NaN      m     sg   \n",
       "3                       de        frau      n    NaN  NaN   NaN      f     sg   \n",
       "4                       de         das    det    NaN  def   NaN     nt     sg   \n",
       "...                    ...         ...    ...    ...  ...   ...    ...    ...   \n",
       "12818386                pt       ajuda  vblex     p3  NaN   pri    NaN     sg   \n",
       "12820232                fr  conférence      n    NaN  NaN   NaN      f     sg   \n",
       "12820235                fr       liens      n    NaN  NaN   NaN      m     pl   \n",
       "12832064                pt         foi  vblex     p3  NaN   ifi    NaN     sg   \n",
       "12844224                fr   compagnie      n    NaN  NaN   NaN      f     sg   \n",
       "\n",
       "          word_len  \n",
       "0                5  \n",
       "1                3  \n",
       "2                4  \n",
       "3                4  \n",
       "4                3  \n",
       "...            ...  \n",
       "12818386         5  \n",
       "12820232        10  \n",
       "12820235         5  \n",
       "12832064         3  \n",
       "12844224         9  \n",
       "\n",
       "[12490 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lexeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "770227\n",
      "1202520\n",
      "798017\n",
      "834768\n",
      "1157685\n",
      "1656996\n"
     ]
    }
   ],
   "source": [
    "# Add SUBTLEX\n",
    "folderpath = os.path.normpath(os.path.join(current_dir, '../data/resources/SUBTLEX'))\n",
    "def prepare_subtlex(folderpath):\n",
    "    dfs = []\n",
    "    for filename in os.listdir(folderpath): \n",
    "        if filename.endswith(\".txt\"):\n",
    "            language = os.path.splitext(filename)[0].split('_')[-2]\n",
    "            filepath = os.path.join(folderpath, filename)\n",
    "            df = pd.read_csv(filepath, on_bad_lines = 'skip', sep=' ', names=['word', 'SUBTLEX'])\n",
    "            print(len(df))\n",
    "            df[\"learning_language\"] = language\n",
    "            dfs.append(df)\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "df_subtlex = prepare_subtlex(folderpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning_language\n",
       "de    2767\n",
       "en    2024\n",
       "es    2865\n",
       "fr    2649\n",
       "it    1102\n",
       "pt    1083\n",
       "dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>learning_language</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "      <th>person</th>\n",
       "      <th>def</th>\n",
       "      <th>tense</th>\n",
       "      <th>gender</th>\n",
       "      <th>number</th>\n",
       "      <th>word_len</th>\n",
       "      <th>SUBTLEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>de</td>\n",
       "      <td>die</td>\n",
       "      <td>det</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>sg</td>\n",
       "      <td>3</td>\n",
       "      <td>2484854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>de</td>\n",
       "      <td>die</td>\n",
       "      <td>det</td>\n",
       "      <td>NaN</td>\n",
       "      <td>def</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mf</td>\n",
       "      <td>pl</td>\n",
       "      <td>3</td>\n",
       "      <td>2484854.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>en</td>\n",
       "      <td>die</td>\n",
       "      <td>vblex</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>214062.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     learning_language word    POS person  def tense gender number  word_len  \\\n",
       "1                   de  die    det    NaN  def   NaN      f     sg         3   \n",
       "558                 de  die    det    NaN  def   NaN     mf     pl         3   \n",
       "3166                en  die  vblex    NaN  NaN   inf    NaN    NaN         3   \n",
       "\n",
       "        SUBTLEX  \n",
       "1     2484854.0  \n",
       "558   2484854.0  \n",
       "3166   214062.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_complexity_df = df_lexeme.merge(df_subtlex, on = ['word', 'learning_language'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.normpath(os.path.join(current_dir, '../data/features/'))\n",
    "word_complexity_df.to_csv(os.path.join(filepath, 'word_complexity_features.csv'), sep='\\t', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for  # Original Dataset§ \n",
    "filename = '13 million Duolingo student learning traces.csv'\n",
    "filepath = os.path.normpath(os.path.join(current_dir, '../data/raw/', filename))\n",
    "\n",
    "\n",
    "chunk_size = 10000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(filepath, chunksize=chunk_size):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "learning_language\n",
       "de    2767\n",
       "en    2024\n",
       "es    2865\n",
       "fr    2649\n",
       "it    1102\n",
       "pt    1083\n",
       "dtype: int64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lexeme.groupby(df['learning_language']).size() # ES, DE and FR have the most words in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

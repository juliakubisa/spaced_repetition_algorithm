{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ae4cfaa-e895-4cfb-8750-5922fd9f0946",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input, Embedding, Flatten, Concatenate, Lambda\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras import regularizers\n",
    "from keras import losses\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split as sklearn_train_test_split\n",
    "from tensorflow.keras.losses import MeanSquaredError\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "#keras.layers.Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97afe127-bec6-41b2-b52d-f32639c50d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def pclip(p):\n",
    "    \"\"\"Clip recall probability to avoid numerical issues.\"\"\"\n",
    "    return p.clip(0.0001, 0.9999)\n",
    "\n",
    "\n",
    "def hclip(h):\n",
    "    min_half_life = 15.0 / (24 * 60)  # 15 minutes in days\n",
    "    max_half_life = 274.0   \n",
    "    \"\"\"Clip half-life to a reasonable range.\"\"\"\n",
    "    return h.clip(min_half_life, max_half_life)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b86d645-8db6-4907-a100-5e4254c38dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "filename = 'df_processed.csv'\n",
    "filepath = os.path.normpath(os.path.join(current_dir, '../data/processed/', filename))\n",
    "\n",
    "chunk_size = 10000\n",
    "chunks = []\n",
    "\n",
    "for chunk in pd.read_csv(filepath, chunksize=chunk_size):\n",
    "    chunk.drop_duplicates(inplace=True)\n",
    "    chunk.dropna(inplace=True)\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "df_users = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../data/features/', 'users_behaviur.csv')))\n",
    "df_words = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../data/features/', 'word_complexity_features.csv')), sep='\\t')\n",
    "dff = pd.merge(pd.merge(df_words, df, on = 'lexeme_id', how='inner'), df_users, on = ['user_id', 'lang_combination'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9d858cdc-e930-44a2-ac43-92362b9aa4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = ['lexeme_id' ,'gender', 'def', 'tense', 'POS', 'person', 'number', 'word', 'session_seen', 'session_correct', 'avg_user_p_recall', 'timestamp', 'user_id', 'learning_language', 'ui_language']\n",
    "dff.drop(columns=cols_to_drop, inplace=True)\n",
    "dff.dropna(inplace=True)\n",
    "\n",
    "\n",
    "dff['delta'] = dff['delta']/(60*60*24) # convert time delta to days\n",
    "dff['avg_delta'] = dff['avg_delta']/(60*60*24) \n",
    "dff['std_delta'] = dff['std_delta']/(60*60*24)\n",
    "dff['p_recall'] = pclip(dff['p_recall'])\n",
    "dff['half_life'] = hclip(-dff['delta']/np.log2(dff['p_recall']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e06b2c84-b914-493f-b89e-f6b6b5ac9266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_len</th>\n",
       "      <th>tags_list</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>p_recall</th>\n",
       "      <th>delta</th>\n",
       "      <th>history_seen</th>\n",
       "      <th>history_correct</th>\n",
       "      <th>h_recall</th>\n",
       "      <th>lang_combination</th>\n",
       "      <th>avg_delta</th>\n",
       "      <th>std_delta</th>\n",
       "      <th>avg_h_recall</th>\n",
       "      <th>half_life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>['vblex', 'pri', 'p3', 'sg']</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.069016</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>en-de</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>0.890225</td>\n",
       "      <td>274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>['vblex', 'pri', 'p3', 'sg']</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>en-de</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>0.890225</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>['vblex', 'pri', 'p3', 'sg']</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>en-de</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>0.890225</td>\n",
       "      <td>5.214388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>['vblex', 'pri', 'p3', 'sg']</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>en-de</td>\n",
       "      <td>0.035931</td>\n",
       "      <td>0.034457</td>\n",
       "      <td>0.890225</td>\n",
       "      <td>0.010417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['vblex', 'pri', 'p3', 'sg']</td>\n",
       "      <td>3391.0</td>\n",
       "      <td>0.9999</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>en-de</td>\n",
       "      <td>1.009879</td>\n",
       "      <td>1.633872</td>\n",
       "      <td>0.914070</td>\n",
       "      <td>14.359623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_len                     tags_list  SUBTLEX  p_recall     delta  \\\n",
       "0         5  ['vblex', 'pri', 'p3', 'sg']   3391.0    0.9999  0.069016   \n",
       "1         5  ['vblex', 'pri', 'p3', 'sg']   3391.0    0.0001  0.002928   \n",
       "2         5  ['vblex', 'pri', 'p3', 'sg']   3391.0    0.9999  0.000752   \n",
       "3         5  ['vblex', 'pri', 'p3', 'sg']   3391.0    0.5000  0.000313   \n",
       "4         5  ['vblex', 'pri', 'p3', 'sg']   3391.0    0.9999  0.002072   \n",
       "\n",
       "   history_seen  history_correct  h_recall lang_combination  avg_delta  \\\n",
       "0             8                6  0.750000            en-de   0.035931   \n",
       "1            14               12  0.857143            en-de   0.035931   \n",
       "2            15               12  0.800000            en-de   0.035931   \n",
       "3            16               13  0.812500            en-de   0.035931   \n",
       "4            15               15  1.000000            en-de   1.009879   \n",
       "\n",
       "   std_delta  avg_h_recall   half_life  \n",
       "0   0.034457      0.890225  274.000000  \n",
       "1   0.034457      0.890225    0.010417  \n",
       "2   0.034457      0.890225    5.214388  \n",
       "3   0.034457      0.890225    0.010417  \n",
       "4   1.633872      0.914070   14.359623  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c933ebf-5ef6-443b-af86-0d4eb4387a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding tags and langs \n",
    "tag_encoder = LabelEncoder()\n",
    "lang_encoder = LabelEncoder()\n",
    "\n",
    "dff['tags_list'] = tag_encoder.fit_transform(dff['tags_list'])\n",
    "dff['lang_combination'] = lang_encoder.fit_transform(dff['lang_combination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "322c5992-95b8-4d23-9394-3302a4ade04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(df):\n",
    "    categorical_features = df.select_dtypes(include='O').columns\n",
    "    numeric_features = df.select_dtypes(exclude=['O']).columns.drop(['p_recall', 'half_life', 'delta'])\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    df[numeric_features] = scaler.fit_transform(df[numeric_features])\n",
    "    return df, categorical_features, numeric_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7885884-1b32-4ae6-bf1a-4155e6f19e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff_1 = dff.copy()\n",
    "dff_1, categorical_features, numeric_features = prepare_dataset(dff_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e778e4bb-6557-4c24-9cba-a01bb815fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "def split(df, numeric_features): \n",
    "    \n",
    "    X = df.drop(columns=['p_recall', 'half_life'])\n",
    "    y = df[['p_recall', 'half_life']]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = sklearn_train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        train_size=0.8,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    X_train_delta = X_train['delta']\n",
    "    X_test_delta = X_test['delta'] \n",
    "    \n",
    "    X_train_numerical = X_train[numeric_features]\n",
    "    X_test_numerical = X_test[numeric_features]\n",
    "\n",
    "    # In case we use encodings \n",
    "    X_train_tags = X_train['tags_list']\n",
    "    X_train_langs = X_train['lang_combination']\n",
    "    X_test_tags = X_test['tags_list']\n",
    "    X_test_langs = X_test['lang_combination']\n",
    "    \n",
    "\n",
    "    # In case we use half-life regression\n",
    "    y_train_p_recall = y_train['p_recall']\n",
    "    y_train_half_life = y_train['half_life']\n",
    "    y_test_p_recall = y_test['p_recall']\n",
    "    y_test_half_life = y_test['half_life']\n",
    "\n",
    "\n",
    "    # Embeddings \n",
    "    return df, X_train_tags, X_train_langs, X_train_numerical, X_test_tags, X_test_langs, X_test_numerical, X_train_delta, X_test_delta, X_test, y_train, y_test, y_train_half_life, y_train_p_recall, y_test_half_life, y_test_p_recall\n",
    "\n",
    "    # No embeddings \n",
    "    # return df, X_train_delta, X_test_delta, X_train_numerical, X_test_numerical, y_train_p_recall, y_train_half_life, y_test_p_recall, y_test_half_life\n",
    "\n",
    "# Embeddings \n",
    "df, X_train_tags, X_train_langs, X_train_numerical, X_test_tags, X_test_langs, X_test_numerical, X_train_delta, X_test_delta, X_test, y_train, y_test, y_train_half_life, y_train_p_recall, y_test_half_life, y_test_p_recall = split(dff_1, numeric_features)\n",
    "\n",
    "\n",
    "# No embeddings\n",
    "# df, X_train_delta, X_test_delta, X_train_numerical, X_test_numerical, y_train_p_recall, y_train_half_life, y_test_p_recall, y_test_half_life = split(dff_1.sample(frac=0.1), numeric_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b7d6ddc4-7782-4a1d-b08b-e17e4d162ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('X_train_tags_size', X_train_tags.shape)\n",
    "# print('X_train_langs_size', X_train_langs.shape)\n",
    "# print('X_train_numerical_size', X_train_numerical.shape)\n",
    "# print('X_test_tags_size', X_test_tags.shape)\n",
    "# print('X_test_langs_size', X_test_langs.shape)\n",
    "# print('X_test_numerical_size', X_test_numerical.shape)\n",
    "# print('y_train_half_life_size', y_train_half_life.shape)\n",
    "# print('y_train_p_recall_size', y_train_p_recall.shape)\n",
    "# print('y_test_half_life_size', y_test_half_life.size)\n",
    "# print('y_test_p_recall_size', y_test_p_recall.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e566998-4b71-4fc5-bb52-9a893bc3d01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "len_tags = len(np.unique(df['tags_list']))\n",
    "len_langs = len(np.unique(df['lang_combination']))\n",
    "\n",
    "embedding_tags_size = int(min(np.ceil((len_tags)/2), 50))\n",
    "embedding_langs_size = int(min(np.ceil((len_langs)/2), 50))\n",
    "\n",
    "tags_input = Input(shape=(1,))  # Reshape input to (None, 1)\n",
    "langs_input = Input(shape=(1,))  # Reshape input to (None, 1)\n",
    "\n",
    "tags_embedded = Embedding(input_dim=len_tags, output_dim=embedding_tags_size)(tags_input)  \n",
    "langs_embedded = Embedding(input_dim=len_langs, output_dim=embedding_langs_size)(langs_input)  \n",
    "\n",
    "flattened_tags = Flatten()(tags_embedded)\n",
    "flattened_langs = Flatten()(langs_embedded)\n",
    "\n",
    "numerical_input = Input(shape=(len(numeric_features),))  # Should be 11\n",
    "delta_input = Input(shape=(1,))  # Time delta (Δ)\n",
    "\n",
    "\n",
    "# Concatenate layers\n",
    "conc = Concatenate()([flattened_tags, flattened_langs, numerical_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "77cae0bc-b67e-4f69-8e11-92cf6cd5301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Architectture\n",
    "# input_dim = X_train.shape[1] \n",
    "hidden_dim = 4         \n",
    "l2wt = 0.1              # L2 regularization weight\n",
    "learning_rate = 0.001\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# no embeddings\n",
    "# x = Dense(hidden_dim, activation=\"relu\", kernel_regularizer=regularizers.l2(l2wt))(numerical_input)\n",
    "\n",
    "# embeddings \n",
    "x = Dense(hidden_dim, activation=\"relu\", kernel_regularizer=regularizers.l2(l2wt))(conc)\n",
    "\n",
    "# For half-life\n",
    "half_life_output = Dense(1, activation=\"relu\", name=\"half_life\")(x) \n",
    "p_recall_output = Lambda(lambda inputs: tf.pow(2.0, -inputs[0] / (inputs[1] + 1e-6)), \n",
    "                         name=\"p_recall\")([delta_input, half_life_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43187307-02b3-4ae2-9d3d-c7273e9a76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nhlr_loss(y_true, y_pred):\n",
    "    h_true, p_true = y_true[0], y_true[1]\n",
    "    h_pred, p_pred = y_pred[0], y_pred[1]\n",
    "\n",
    "    slh = tf.reduce_mean(tf.square(h_true - h_pred)) # half-life loss \n",
    "    slp = tf.reduce_mean(tf.square(p_true - p_pred)) # p_recall loss \n",
    "\n",
    "    return slp + slh \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "293b1641-b989-43c9-b236-07bc97d9c9f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max tag index: 1.0 Embedding input_dim: 401\n",
      "Max lang index: 1.0 Embedding input_dim: 8\n",
      "Tags Input Shape: (None, 1)\n",
      "Langs Input Shape: (None, 1)\n",
      "Numerical Input Shape: (None, 10)\n",
      "Flattened tags Embedded Shape: (None, 50)\n",
      "Flattened Langs Embedded Shape: (None, 4)\n",
      "Flattened Numerical Input Shape: (None, 10)\n",
      "X_train_tags shape: (10004398,)\n",
      "X_train_langs shape: (10004398,)\n",
      "X_train_numerical shape: (10004398, 10)\n",
      "X_train_delta shape: (10004398,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Max tag index:\", X_train_tags.max(), \"Embedding input_dim:\", len_tags)\n",
    "print(\"Max lang index:\", X_train_langs.max(), \"Embedding input_dim:\", len_langs)\n",
    "\n",
    "print(\"Tags Input Shape:\", tags_input.shape)\n",
    "print(\"Langs Input Shape:\", langs_input.shape)\n",
    "print(\"Numerical Input Shape:\", numerical_input.shape)\n",
    "\n",
    "print(\"Flattened tags Embedded Shape:\", flattened_tags.shape)\n",
    "print(\"Flattened Langs Embedded Shape:\", flattened_langs.shape)\n",
    "print(\"Flattened Numerical Input Shape:\", numerical_input.shape)\n",
    "\n",
    "print(\"X_train_tags shape:\", X_train_tags.shape)    # Should be (batch_size, 1)\n",
    "print(\"X_train_langs shape:\", X_train_langs.shape)  # Should be (batch_size, 1)\n",
    "print(\"X_train_numerical shape:\", X_train_numerical.shape)  \n",
    "print(\"X_train_delta shape:\", X_train_delta.shape)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0c630a65-ba19-479d-9024-ce9e33974759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor shape=(None, 1), dtype=float32, sparse=False, name=keras_tensor_46>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langs_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "51a0bccc-e1c5-454d-8978-8ea1d6e27604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "312638/312638 - 149s - 475us/step - half_life_MAE: 120.3035 - half_life_loss: 30443.1973 - loss: 30522.3086 - p_recall_MAE: 0.1173 - p_recall_loss: 0.1624\n",
      "Epoch 2/10\n",
      "312638/312638 - 147s - 471us/step - half_life_MAE: 118.3181 - half_life_loss: 29826.4609 - loss: 29981.0000 - p_recall_MAE: 0.1161 - p_recall_loss: 0.1603\n",
      "Epoch 3/10\n",
      "312638/312638 - 150s - 480us/step - half_life_MAE: 117.5639 - half_life_loss: 29653.5781 - loss: 29800.0098 - p_recall_MAE: 0.1159 - p_recall_loss: 0.1610\n",
      "Epoch 4/10\n",
      "312638/312638 - 151s - 484us/step - half_life_MAE: 117.2330 - half_life_loss: 29559.7715 - loss: 29692.9160 - p_recall_MAE: 0.1159 - p_recall_loss: 0.1608\n",
      "Epoch 5/10\n",
      "312638/312638 - 146s - 466us/step - half_life_MAE: 117.0651 - half_life_loss: 29517.3516 - loss: 29641.6504 - p_recall_MAE: 0.1159 - p_recall_loss: 0.1608\n",
      "Epoch 6/10\n",
      "312638/312638 - 151s - 483us/step - half_life_MAE: 116.9837 - half_life_loss: 29510.9258 - loss: 29625.6074 - p_recall_MAE: 0.1159 - p_recall_loss: 0.1612\n",
      "Epoch 7/10\n",
      "312638/312638 - 152s - 486us/step - half_life_MAE: 116.9158 - half_life_loss: 29476.9375 - loss: 29580.8164 - p_recall_MAE: 0.1158 - p_recall_loss: 0.1597\n",
      "Epoch 8/10\n",
      "312638/312638 - 152s - 486us/step - half_life_MAE: 116.9002 - half_life_loss: 29487.0391 - loss: 29582.2520 - p_recall_MAE: 0.1159 - p_recall_loss: 0.1609\n",
      "Epoch 9/10\n",
      "312638/312638 - 150s - 481us/step - half_life_MAE: 116.8722 - half_life_loss: 29447.9609 - loss: 29535.4492 - p_recall_MAE: 0.1158 - p_recall_loss: 0.1604\n",
      "Epoch 10/10\n",
      "312638/312638 - 149s - 477us/step - half_life_MAE: 116.8608 - half_life_loss: 29459.7266 - loss: 29542.7148 - p_recall_MAE: 0.1158 - p_recall_loss: 0.1606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x16a31b5f0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no embeddings\n",
    "# model = Model(inputs=[numerical_input, delta_input], outputs=[half_life_output, p_recall_output])\n",
    "\n",
    "# embeddings \n",
    "model = Model(inputs=[tags_input, langs_input, numerical_input, delta_input], outputs=[half_life_output, p_recall_output])\n",
    "\n",
    "model.compile(loss=nhlr_loss, optimizer= Adam(learning_rate=learning_rate), metrics=['MAE', 'MAE'])\n",
    "\n",
    "# no embeddings \n",
    "# model.fit([X_train_numerical, X_train_delta], [y_train_half_life, y_train_p_recall], epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "# embeddings \n",
    "model.fit([X_train_tags, X_train_langs, X_train_numerical, X_train_delta], [y_train_half_life, y_train_p_recall], epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "\n",
    "# Without half lfie \n",
    "# model.fit([X_train_tags, X_train_langs, X_train_numerical], y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3781b244-4446-4aa1-a79f-d62d48df995e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m78160/78160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 302us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_half_life, y_pred_p_recall  = model.predict([X_test_tags, X_test_langs, X_test_numerical, X_test_delta])\n",
    "\n",
    "y_test['p_recall_pred'] = y_pred_p_recall\n",
    "y_test['half_life_pred'] = y_pred_half_life"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2a6adb3c-315b-4359-8262-84d5b80c7309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final MAE - p_recall: 0.1157\n"
     ]
    }
   ],
   "source": [
    "mae_p = np.mean(np.abs(y_test['p_recall'] - y_test['p_recall_pred']))\n",
    "mae_h = np.mean(np.abs(y_test['half_life'] - y_test['half_life_pred']))\n",
    "\n",
    "print(f\"Final MAE - p_recall: {mae_p:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b055626-5f5e-441d-b333-f0be9b6f70bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>half_life</th>\n",
       "      <th>p_recall_pred</th>\n",
       "      <th>half_life_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2501100.00000</td>\n",
       "      <td>2501100.00000</td>\n",
       "      <td>2501100.00000</td>\n",
       "      <td>2501100.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.89736</td>\n",
       "      <td>155.58351</td>\n",
       "      <td>0.97944</td>\n",
       "      <td>154.63060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.26974</td>\n",
       "      <td>124.07122</td>\n",
       "      <td>0.04045</td>\n",
       "      <td>25.28597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.01042</td>\n",
       "      <td>0.39903</td>\n",
       "      <td>1.82996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>19.10324</td>\n",
       "      <td>0.97904</td>\n",
       "      <td>141.14271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>274.00000</td>\n",
       "      <td>0.99618</td>\n",
       "      <td>153.11523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>274.00000</td>\n",
       "      <td>0.99997</td>\n",
       "      <td>165.37991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.99990</td>\n",
       "      <td>274.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>450.57632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p_recall      half_life  p_recall_pred half_life_pred\n",
       "count  2501100.00000  2501100.00000  2501100.00000  2501100.00000\n",
       "mean         0.89736      155.58351        0.97944      154.63060\n",
       "std          0.26974      124.07122        0.04045       25.28597\n",
       "min          0.00010        0.01042        0.39903        1.82996\n",
       "25%          0.99990       19.10324        0.97904      141.14271\n",
       "50%          0.99990      274.00000        0.99618      153.11523\n",
       "75%          0.99990      274.00000        0.99997      165.37991\n",
       "max          0.99990      274.00000        1.00000      450.57632"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.describe().apply(lambda s: s.apply('{0:.5f}'.format))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b398f546-bf99-4641-84c7-e7be5ada8bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

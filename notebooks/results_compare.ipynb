{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdaebf45-e33a-48eb-9785-9ad626f2a608",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69356d87-7ee0-4216-a7f6-100d78299833",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "\n",
    "\n",
    "fnn_output = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../results/', 'fnn_output.csv')), sep='\\t')\n",
    "hnn_output = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../results/', 'hmm_output.csv')), sep='\\t')\n",
    "hlr_output = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../results/', 'hlr_output.csv')), sep='\\t')\n",
    "lr_output = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../results/', 'linear_regression_output.csv')), sep='\\t')\n",
    "xgboost_output = pd.read_csv(os.path.normpath(os.path.join(current_dir, '../results/', 'xgboost.csv')), sep='\\t')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "476c32b0-8124-45ca-b0ba-1a0cef758282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall</th>\n",
       "      <th>p_recall_pred</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.889664</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.879037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.879037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.879037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.879037</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535498</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.881564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535499</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.881564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535500</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.881564</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535501</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.940124</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4535502</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.929467</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4535503 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p_recall  p_recall_pred  outcome\n",
       "0        1.000000       0.889664      1.0\n",
       "1        0.857143       0.879037      1.0\n",
       "2        0.857143       0.879037      1.0\n",
       "3        0.857143       0.879037      1.0\n",
       "4        0.857143       0.879037      1.0\n",
       "...           ...            ...      ...\n",
       "4535498  0.666667       0.881564      1.0\n",
       "4535499  0.666667       0.881564      1.0\n",
       "4535500  0.666667       0.881564      0.0\n",
       "4535501  1.000000       0.940124      1.0\n",
       "4535502  1.000000       0.929467      1.0\n",
       "\n",
       "[4535503 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgboost_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fda28598-6d96-4856-aae9-32d9a4ec9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgboost_output = xgboost_output.rename(columns={\"y_test\": \"p_recall\", \"y_pred\": \"p_recall_pred\"}, errors=\"raise\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "348da2f4-0a00-484d-a396-fce93c59f517",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_output = lr_output.rename(columns={\"predictions\":\"p_recall_pred\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51ccfa94-7dc6-4e75-852b-220622a0e636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_recall_pred</th>\n",
       "      <th>p_recall</th>\n",
       "      <th>outcome</th>\n",
       "      <th>decile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.938091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.938091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.885309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.885309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885309</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614509</th>\n",
       "      <td>0.867557</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614510</th>\n",
       "      <td>0.927240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614511</th>\n",
       "      <td>0.927240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614512</th>\n",
       "      <td>0.927240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4614513</th>\n",
       "      <td>0.927240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4614514 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         p_recall_pred  p_recall  outcome  decile\n",
       "0             0.938091       1.0      1.0       2\n",
       "1             0.938091       1.0      1.0       2\n",
       "2             0.885309       1.0      1.0       7\n",
       "3             0.885309       1.0      1.0       7\n",
       "4             0.885309       1.0      1.0       7\n",
       "...                ...       ...      ...     ...\n",
       "4614509       0.867557       1.0      1.0       8\n",
       "4614510       0.927240       1.0      1.0       3\n",
       "4614511       0.927240       1.0      1.0       3\n",
       "4614512       0.927240       1.0      1.0       3\n",
       "4614513       0.927240       1.0      1.0       3\n",
       "\n",
       "[4614514 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8ca5eaa-a8ed-4b1b-a266-2145b9243062",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [fnn_output, hnn_output, hlr_output, lr_output, xgboost_output]\n",
    "labels = [\"fnn\", \"n-hlr\", \"hlr\", \"lr\", \"xgboost\"] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b8e9895f-691a-4c5e-9b61-0c7634eab13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC_ROC(datasets, labels, filename):\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    for df, label in zip(datasets, labels):\n",
    "\n",
    "        outcome = df['outcome']\n",
    "        outcome_prob = df['p_recall_pred']\n",
    "        \n",
    "        # Calculate ROC curve and AUC\n",
    "        fpr, tpr, _ = roc_curve(outcome, outcome_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.plot(fpr, tpr, label=f\"{label} (AUC = {roc_auc:.3f})\", linewidth=2)\n",
    "        print(f\"{label} - AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Plot random guess line\n",
    "    plt.plot([0, 1], [0, 1], 'k--', label=\"Random (AUC = 0.500)\")\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve Comparison')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9212c00-f0e6-407f-880e-83db5d556561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fnn - AUC: 0.6014\n",
      "hnn - AUC: 0.5320\n",
      "hlr - AUC: 0.5290\n",
      "lr - AUC: 0.6159\n",
      "xgboost - AUC: 0.6548\n"
     ]
    }
   ],
   "source": [
    "AUC_ROC(datasets, labels, \"roc_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c40b33a-e28e-4d81-b0ca-901f72d89251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lift(datasets, outcome_col, outcome_prob_col, labels, filename):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - datasets: List of DataFrames, each containing outcome and predicted probability columns.\n",
    "    - outcome_col: Name of the column with true outcomes (e.g., 'outcome').\n",
    "    - outcome_prob_col: Name of the column with predicted probabilities (e.g., 'p_recall_pred').\n",
    "    - labels: List of labels for each dataset (for legend).\n",
    "    - filename: Output filename for the plot.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = plt.cm.tab10.colors  # Use a color palette for clarity\n",
    "\n",
    "    for idx, (df, label) in enumerate(zip(datasets, labels)):\n",
    "        # Calculate deciles (1 = highest predictions)\n",
    "        df[\"decile\"] = pd.qcut(\n",
    "            df[outcome_prob_col].rank(method=\"first\", ascending=False),\n",
    "            10,\n",
    "            labels=False,\n",
    "        ) + 1\n",
    "\n",
    "        # Group by decile and calculate lift\n",
    "        lift_df = df.groupby(\"decile\")[outcome_col].agg([\"mean\", \"count\"])\n",
    "        baseline_rate = df[outcome_col].mean()\n",
    "        lift_df[\"lift\"] = lift_df[\"mean\"] / baseline_rate\n",
    "\n",
    "        # Plot lift curve\n",
    "        plt.plot(\n",
    "            lift_df.index,\n",
    "            lift_df[\"lift\"],\n",
    "            marker=\"o\",\n",
    "            linestyle=\"-\",\n",
    "            color=colors[idx],\n",
    "            label=f\"{label}\",\n",
    "        )\n",
    "\n",
    "    # Add baseline and styling\n",
    "    plt.axhline(y=1, color=\"gray\", linestyle=\"--\", label=\"Overall Baseline (1x)\")\n",
    "    plt.xlabel(\"Decile (1 = Highest Predictions)\")\n",
    "    plt.ylabel(\"Lift\")\n",
    "    plt.title(\"Lift Chart Comparison\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.grid(True)\n",
    "    plt.xticks(range(1, 11))  # Ensure all deciles are shown\n",
    "\n",
    "    plt.savefig(filename, bbox_inches='tight', dpi=300)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "daa35a22-667f-4da4-a128-f67c5ebc178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lift(datasets, \"outcome\", \"p_recall_pred\", labels, \"lift_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "778a1ab4-c4d7-413d-ab43-81cb2f8e57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_calibration(datasets, outcome_col, outcome_prob_col, labels, filename, n_bins=10):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    - datasets: List of DataFrames, each containing outcome and predicted probability columns.\n",
    "    - outcome_col: Name of the column with true outcomes (e.g., 'outcome').\n",
    "    - outcome_prob_col: Name of the column with predicted probabilities (e.g., 'p_recall_pred').\n",
    "    - labels: List of labels for each dataset (for legend).\n",
    "    - filename: Output filename for the plot.\n",
    "    - n_bins: Number of bins for calibration curve (default: 10).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = plt.cm.tab10.colors  # Use a color palette for clarity\n",
    "\n",
    "    for idx, (df, label) in enumerate(zip(datasets, labels)):\n",
    "        # Extract true labels and predicted probabilities\n",
    "        outcome = df[outcome_col]\n",
    "        outcome_prob = df[outcome_prob_col]\n",
    "\n",
    "        # Calculate calibration curve\n",
    "        prob_true, prob_pred = calibration_curve(outcome, outcome_prob, n_bins=n_bins)\n",
    "\n",
    "        # Plot calibration curve\n",
    "        plt.plot(\n",
    "            prob_pred,\n",
    "            prob_true,\n",
    "            \"s-\",  # Square markers with solid lines\n",
    "            color=colors[idx],\n",
    "            label=f\"{label}\",\n",
    "            markersize=6,\n",
    "        )\n",
    "\n",
    "    # Plot perfect calibration line\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfectly Calibrated\")\n",
    "    plt.xlabel(\"Mean Predicted Probability\")\n",
    "    plt.ylabel(\"Observed Frequency\")\n",
    "    plt.title(\"Calibration Plot Comparison\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True)\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "\n",
    "    plt.savefig(filename, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3d012eb9-ba91-4f90-ac68-b5eb471cf264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the plot\n",
    "plot_calibration(datasets, \"outcome\", \"p_recall_pred\", labels, \"calibration_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee37aec0-f8c3-49a2-9468-c1a4565d651e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
